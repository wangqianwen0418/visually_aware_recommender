{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from io import StringIO, BytesIO\n",
    "from PIL import Image\n",
    "from scipy.misc import imresize\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\" # only use GPU 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_name = 'AmazonFashion6ImgPartitioned.npy'\n",
    "dataset_dir = '../dataset/amazon/'\n",
    "dataset = np.load(dataset_dir + dataset_name, encoding = 'bytes')\n",
    "\n",
    "[user_train, user_validation, user_test, Item, usernum, itemnum] = dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(img_s, mean=np.array([0.43, 0.47, 0.49]), std=np.array([1.0, 1.0, 1.0])):\n",
    "    return (imresize(np.asarray(Image.open(BytesIO(img_s))), (224, 224, 3)) / 255 - np.array(mean)) / np.array(std)\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self, source, batch_size=32, dim=(224, 224, 3)):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.source = source\n",
    "        \n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.source) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Sampling\n",
    "        X = {'input_i': np.empty((self.batch_size, *self.dim)), \n",
    "             'input_j': np.empty((self.batch_size, *self.dim)),\n",
    "             'input_user': np.empty((self.batch_size), dtype=int)}\n",
    "        y = np.ones((self.batch_size), dtype=int)\n",
    "        for k in range(self.batch_size):\n",
    "            u = random.randint(0, len(self.source)-1)\n",
    "            X['input_user'][k] = int(u)\n",
    "            u_imgs = list(set([e[b'productid'] for e in self.source[u]]))\n",
    "            \n",
    "            i = u_imgs[random.randint(0, len(u_imgs)-1)]\n",
    "            X['input_i'][k] = preprocess(Item[i][b'imgs'])\n",
    "            j = random.randint(0, len(Item)-1)\n",
    "            while j in u_imgs:\n",
    "                j = random.randint(0, len(Item)-1)\n",
    "            X['input_j'][k] = preprocess(Item[j][b'imgs'])\n",
    "        return X, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape [(None, 10, 1), (None, 1)]\n",
      "input shape [(None, 10, 1), (None, 1)]\n"
     ]
    }
   ],
   "source": [
    "w = 224\n",
    "h = 224\n",
    "input_shape = (w, h, 3)\n",
    "dropout = 0.2\n",
    "latent_d = 10 # latent dimension\n",
    "\n",
    "user_num = 1000 # for test, this should be obtained from the dataset\n",
    "\n",
    "\n",
    "def euclidean_distance(vects): \n",
    "    # L2 distance\n",
    "    x, y = vects\n",
    "    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
    "    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
    "\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "input_i = layers.Input(shape=input_shape, name=\"input_i\") # image of item i\n",
    "input_j = layers.Input(shape=input_shape, name=\"input_j\") # image of item j\n",
    "input_idx = layers.Input(shape=[1], name=\"input_user\", dtype='int32') # idx of user u\n",
    "\n",
    "\n",
    "# customer layer, learn the latent matrix of theta_u\n",
    "class ThetaLayer(Layer):\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        # Create a trainable weight variable for this layer.\n",
    "        self.kernel = self.add_weight(name='theta_u_matrix', \n",
    "                                      shape=(user_num, latent_d),\n",
    "                                      initializer='uniform',\n",
    "                                      trainable=True)\n",
    "        super(ThetaLayer, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, x):\n",
    "        assert isinstance(x, list)\n",
    "        item, u = x # u: user idx; item: visual feature of item \n",
    "        return K.dot(K.gather(self.kernel, u), item)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        print('input shape', input_shape)\n",
    "        return (input_shape[0][0], 1)\n",
    "\n",
    "\n",
    "# load the VGG pretrained on imagenet\n",
    "def create_base_vgg(dropout):\n",
    "    vgg = keras.applications.vgg19.VGG19(\n",
    "        include_top=False, # whether to include the fc layers\n",
    "        weights='imagenet', \n",
    "        input_tensor=None, \n",
    "        input_shape=input_shape, \n",
    "        pooling='avg',  # in my experience, gloable avg works better than flatten, need to check\n",
    "        classes=1000)\n",
    "    x = vgg.output\n",
    "#     x = layers.Flatten(name='flatten')(x)\n",
    "    x = layers.Dense(256, activation='relu', name='fc1')(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Dense(latent_d, activation='relu', name='predictions')(x)\n",
    "    x = layers.Reshape(target_shape=(latent_d, 1))(x)\n",
    "    \n",
    "    return Model(inputs = vgg.input, outputs = x, name=\"base_vgg\")\n",
    "\n",
    "\n",
    "\n",
    "# because we re-use the same instance `base_vgg`, theta_layer,\n",
    "# the weights of the network\n",
    "# will be shared across the two branches\n",
    "base_vgg = create_base_vgg(dropout)\n",
    "theta = ThetaLayer(name='theta_layer')\n",
    "\n",
    "x1 = base_vgg(input_i)\n",
    "x1 = theta([x1, input_idx])\n",
    "\n",
    "x2 = base_vgg(input_j)\n",
    "x2 = theta([x2, input_idx])\n",
    "\n",
    "# distance = layers.Lambda(euclidean_distance,\n",
    "#                   output_shape=eucl_dist_output_shape)([x1, x2])\n",
    "            \n",
    "distance = layers.Subtract(name='substract')([x1, x2])\n",
    "distance = layers.Activation(activation='sigmoid', name='sigmoid')(distance)\n",
    "\n",
    "model = Model([input_i, input_j, input_idx], distance)\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "# -----------Evaluation---------------\n",
    "# evaluation is different from training, \n",
    "# input of training: [user u, item i, item j]; \n",
    "# input of evaluation: [user u, item i]\n",
    "# predict_score = layers.Activation(activation='sigmoid')(x1)\n",
    "# evaluation_model = Model([input_i, input_idx], predict_score)\n",
    "# evaluation_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class history(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 30\n",
    "# loss function\n",
    "def simple_BPR_loss(y_true, y_pred):\n",
    "    return -K.sum(y_pred)\n",
    "\n",
    "# first: freeze all convolutional layers, only train fc layers (which were randomly initialized)\n",
    "# set trainable layers before model compile\n",
    "for layer in base_vgg.layers[:-4]:\n",
    "    layer.trainable = False\n",
    "for layer in base_vgg.layers[-4:]:\n",
    "    layer.trainable = True\n",
    "# adam optimizer\n",
    "adam = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(optimizer=adam, loss=simple_BPR_loss)\n",
    "\n",
    "training_generator = DataGenerator(user_train)\n",
    "validation_generator = DataGenerator(user_validation)\n",
    "\n",
    "model.fit_generator(generator=training_generator,\n",
    "                   validation_data=validation_generator)\n",
    "# model.fit(x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None)\n",
    "# evaluation_model.evaluate(x=None, y=None, batch_size=None, verbose=1, sample_weight=None, steps=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
